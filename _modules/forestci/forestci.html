<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>forestci.forestci &mdash; forestci 0.6 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/project-template.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/copybutton.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> forestci
          </a>
              <div class="version">
                0.6
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation_guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html"><code class="docutils literal notranslate"><span class="pre">forestci</span></code> API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing to <code class="docutils literal notranslate"><span class="pre">forestci</span></code> development</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">forestci</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>forestci.forestci</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for forestci.forestci</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Forest confidence intervals.</span>

<span class="sd">Calculate confidence intervals for scikit-learn RandomForestRegressor and</span>
<span class="sd">RandomForestClassifier predictions.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble._forest</span> <span class="kn">import</span> <span class="n">BaseForest</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble._forest</span> <span class="kn">import</span> <span class="p">(</span><span class="n">_generate_sample_indices</span><span class="p">,</span>
                                      <span class="n">_get_n_samples_bootstrap</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble._bagging</span> <span class="kn">import</span> <span class="n">BaseBagging</span>

<span class="kn">from</span> <span class="nn">.calibration</span> <span class="kn">import</span> <span class="n">calibrateEB</span>
<span class="kn">from</span> <span class="nn">.due</span> <span class="kn">import</span> <span class="n">_due</span><span class="p">,</span> <span class="n">_BibTeX</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;calc_inbag&quot;</span><span class="p">,</span> <span class="s2">&quot;random_forest_error&quot;</span><span class="p">,</span> <span class="s2">&quot;_bias_correction&quot;</span><span class="p">,</span>
           <span class="s2">&quot;_core_computation&quot;</span><span class="p">)</span>

<span class="n">_due</span><span class="o">.</span><span class="n">cite</span><span class="p">(</span>
    <span class="n">_BibTeX</span><span class="p">(</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">@ARTICLE{Wager2014-wn,</span>
<span class="sd">  title       = &quot;Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife&quot;,</span>
<span class="sd">  author      = &quot;Wager, Stefan and Hastie, Trevor and Efron, Bradley&quot;,</span>
<span class="sd">  journal     = &quot;J. Mach. Learn. Res.&quot;,</span>
<span class="sd">  volume      =  15,</span>
<span class="sd">  number      =  1,</span>
<span class="sd">  pages       = &quot;1625--1651&quot;,</span>
<span class="sd">  month       =  jan,</span>
<span class="sd">  year        =  2014,}&quot;&quot;&quot;</span>
    <span class="p">),</span>
    <span class="n">description</span><span class="o">=</span><span class="p">(</span>
        <span class="s2">&quot;Confidence Intervals for Random Forests:&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The Jackknife and the Infinitesimal Jackknife&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">path</span><span class="o">=</span><span class="s2">&quot;forestci&quot;</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">calc_inbag</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">forest</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Derive samples used to create trees in scikit-learn RandomForest objects.</span>

<span class="sd">    Recovers the samples in each tree from the random state of that tree using</span>
<span class="sd">    :func:`forest._generate_sample_indices`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        The number of samples used to fit the scikit-learn RandomForest object.</span>

<span class="sd">    forest : RandomForest</span>
<span class="sd">        Regressor or Classifier object that is already fit by scikit-learn.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Array that records how many times a data point was placed in a tree.</span>
<span class="sd">    Columns are individual trees. Rows are the number of times a sample was</span>
<span class="sd">    used in a tree.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">forest</span><span class="o">.</span><span class="n">bootstrap</span><span class="p">:</span>
        <span class="n">e_s</span> <span class="o">=</span> <span class="s2">&quot;Cannot calculate the inbag from a forest that has bootstrap=False&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">e_s</span><span class="p">)</span>

    <span class="n">n_trees</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">n_estimators</span>
    <span class="n">inbag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">))</span>
    <span class="n">sample_idx</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">BaseForest</span><span class="p">):</span>
        <span class="n">n_samples_bootstrap</span> <span class="o">=</span> <span class="n">_get_n_samples_bootstrap</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">forest</span><span class="o">.</span><span class="n">max_samples</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">t_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trees</span><span class="p">):</span>
            <span class="n">sample_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_generate_sample_indices</span><span class="p">(</span>
                    <span class="n">forest</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">t_idx</span><span class="p">]</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">n_samples</span><span class="p">,</span>
                    <span class="n">n_samples_bootstrap</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">inbag</span><span class="p">[:,</span> <span class="n">t_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">sample_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">minlength</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">BaseBagging</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">t_idx</span><span class="p">,</span> <span class="n">estimator_sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">forest</span><span class="o">.</span><span class="n">estimators_samples_</span><span class="p">):</span>
            <span class="n">sample_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimator_sample</span><span class="p">)</span>
            <span class="n">inbag</span><span class="p">[:,</span> <span class="n">t_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">sample_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">minlength</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">inbag</span>


<span class="k">def</span> <span class="nf">_core_computation</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">inbag</span><span class="p">,</span>
    <span class="n">pred_centered</span><span class="p">,</span>
    <span class="n">n_trees</span><span class="p">,</span>
    <span class="n">memory_constrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">memory_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">test_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function, that performs the core computation</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_train : ndarray</span>
<span class="sd">        An array with shape (n_train_sample, n_features).</span>

<span class="sd">    X_test : ndarray</span>
<span class="sd">        An array with shape (n_test_sample, n_features).</span>

<span class="sd">    inbag : ndarray</span>
<span class="sd">        The inbag matrix that fit the data. If set to `None` (default) it</span>
<span class="sd">        will be inferred from the forest. However, this only works for trees</span>
<span class="sd">        for which bootstrapping was set to `True`. That is, if sampling was</span>
<span class="sd">        done with replacement. Otherwise, users need to provide their own</span>
<span class="sd">        inbag matrix.</span>

<span class="sd">    pred_centered : ndarray</span>
<span class="sd">        Centered predictions that are an intermediate result in the</span>
<span class="sd">        computation.</span>

<span class="sd">    memory_constrained: boolean (optional)</span>
<span class="sd">        Whether or not there is a restriction on memory. If False, it is</span>
<span class="sd">        assumed that a ndarry of shape (n_train_sample,n_test_sample) fits</span>
<span class="sd">        in main memory. Setting to True can actually provide a speed up if</span>
<span class="sd">        memory_limit is tuned to the optimal range.</span>

<span class="sd">    memory_limit: int (optional)</span>
<span class="sd">        An upper bound for how much memory the itermediate matrices will take</span>
<span class="sd">        up in Megabytes. This must be provided if memory_constrained=True.</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">memory_constrained</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inbag</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pred_centered</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_trees</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">memory_limit</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;If memory_constrained=True, must provide&quot;</span><span class="p">,</span> <span class="s2">&quot;memory_limit.&quot;</span><span class="p">)</span>

    <span class="c1"># Assumes double precision float</span>
    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">memory_limit</span> <span class="o">*</span> <span class="mf">1e6</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">8.0</span> <span class="o">*</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">chunk_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">min_limit</span> <span class="o">=</span> <span class="mf">8.0</span> <span class="o">*</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e6</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;memory_limit provided is too small.&quot;</span>
            <span class="o">+</span> <span class="s2">&quot;For these dimensions, memory_limit must &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;be greater than or equal to </span><span class="si">%.3e</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">min_limit</span>
        <span class="p">)</span>

    <span class="n">chunk_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
    <span class="n">inds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">inds</span><span class="p">[</span><span class="n">chunk_edges</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">:</span> <span class="n">chunk_edges</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk_edges</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">test_mode</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of chunks: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">),))</span>
    <span class="n">V_IJ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inbag</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pred_centered</span><span class="p">[</span><span class="n">chunk</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_trees</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">V_IJ</span>


<span class="k">def</span> <span class="nf">_bias_correction</span><span class="p">(</span><span class="n">V_IJ</span><span class="p">,</span> <span class="n">inbag</span><span class="p">,</span> <span class="n">pred_centered</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper functions that implements bias correction</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    V_IJ : ndarray</span>
<span class="sd">        Intermediate result in the computation.</span>

<span class="sd">    inbag : ndarray</span>
<span class="sd">        The inbag matrix that fit the data. If set to `None` (default) it</span>
<span class="sd">        will be inferred from the forest. However, this only works for trees</span>
<span class="sd">        for which bootstrapping was set to `True`. That is, if sampling was</span>
<span class="sd">        done with replacement. Otherwise, users need to provide their own</span>
<span class="sd">        inbag matrix.</span>

<span class="sd">    pred_centered : ndarray</span>
<span class="sd">        Centered predictions that are an intermediate result in the</span>
<span class="sd">        computation.</span>

<span class="sd">    n_trees : int</span>
<span class="sd">        The number of trees in the forest object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_train_samples</span> <span class="o">=</span> <span class="n">inbag</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">inbag</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n_trees</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">view</span><span class="p">()</span>
        <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">inbag</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n_trees</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">view</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">boot_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">pred_centered</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_trees</span>
    <span class="n">bias_correction</span> <span class="o">=</span> <span class="n">n_train_samples</span> <span class="o">*</span> <span class="n">n_var</span> <span class="o">*</span> <span class="n">boot_var</span> <span class="o">/</span> <span class="n">n_trees</span>
    <span class="n">V_IJ_unbiased</span> <span class="o">=</span> <span class="n">V_IJ</span> <span class="o">-</span> <span class="n">bias_correction</span>
    <span class="k">return</span> <span class="n">V_IJ_unbiased</span>


<span class="k">def</span> <span class="nf">_centered_prediction_forest</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Center the tree predictions by the mean prediction (forest)</span>

<span class="sd">    The centering is done for all provided test samples.</span>
<span class="sd">    This function allows unit testing for internal correctness.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    forest : RandomForest</span>
<span class="sd">        Regressor or Classifier object.</span>

<span class="sd">    X_test : ndarray</span>
<span class="sd">        An array with shape (n_test_sample, n_features). The design matrix</span>
<span class="sd">        for testing data</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pred_centered : ndarray</span>
<span class="sd">        An array with shape (n_test_sample, n_estimators).</span>
<span class="sd">        The predictions of each single tree centered by the</span>
<span class="sd">        mean prediction (i.e. the prediction of the forest)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># reformatting required for single sample arrays</span>
    <span class="c1"># caution: assumption that number of features always &gt; 1</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># reshape according to the reshaping annotation in scikit-learn</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="k">for</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">forest</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">pred_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">pred_mean</span>


<div class="viewcode-block" id="random_forest_error"><a class="viewcode-back" href="../../generated/forestci.random_forest_error.html#forestci.random_forest_error">[docs]</a><span class="k">def</span> <span class="nf">random_forest_error</span><span class="p">(</span>
    <span class="n">forest</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">inbag</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">calibrate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">memory_constrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">memory_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate error bars from scikit-learn RandomForest estimators.</span>

<span class="sd">    RandomForest is a regressor or classifier object</span>
<span class="sd">    this variance can be used to plot error bars for RandomForest objects</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    forest : RandomForest</span>
<span class="sd">        Regressor or Classifier object.</span>

<span class="sd">    X_train : ndarray</span>
<span class="sd">        An array with shape (n_train_sample, n_features). The design matrix for</span>
<span class="sd">        training data.</span>

<span class="sd">    X_test : ndarray</span>
<span class="sd">        An array with shape (n_test_sample, n_features). The design matrix</span>
<span class="sd">        for testing data</span>

<span class="sd">    inbag : ndarray, optional</span>
<span class="sd">        The inbag matrix that fit the data. If set to `None` (default) it</span>
<span class="sd">        will be inferred from the forest. However, this only works for trees</span>
<span class="sd">        for which bootstrapping was set to `True`. That is, if sampling was</span>
<span class="sd">        done with replacement. Otherwise, users need to provide their own</span>
<span class="sd">        inbag matrix.</span>

<span class="sd">    calibrate: boolean, optional</span>
<span class="sd">        Whether to apply calibration to mitigate Monte Carlo noise.</span>
<span class="sd">        Some variance estimates may be negative due to Monte Carlo effects if</span>
<span class="sd">        the number of trees in the forest is too small. To use calibration,</span>
<span class="sd">        Default: True</span>

<span class="sd">    memory_constrained: boolean, optional</span>
<span class="sd">        Whether or not there is a restriction on memory. If False, it is</span>
<span class="sd">        assumed that a ndarry of shape (n_train_sample,n_test_sample) fits</span>
<span class="sd">        in main memory. Setting to True can actually provide a speed up if</span>
<span class="sd">        memory_limit is tuned to the optimal range.</span>

<span class="sd">    memory_limit: int, optional.</span>
<span class="sd">        An upper bound for how much memory the itermediate matrices will take</span>
<span class="sd">        up in Megabytes. This must be provided if memory_constrained=True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    An array with the unbiased sampling variance (V_IJ_unbiased)</span>
<span class="sd">    for a RandomForest object.</span>

<span class="sd">    See Also</span>
<span class="sd">    ----------</span>
<span class="sd">    :func:`calc_inbag`</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The calculation of error is based on the infinitesimal jackknife variance,</span>
<span class="sd">    as described in [Wager2014]_ and is a Python implementation of the R code</span>
<span class="sd">    provided at: https://github.com/swager/randomForestCI</span>

<span class="sd">    .. [Wager2014] S. Wager, T. Hastie, B. Efron. &quot;Confidence Intervals for</span>
<span class="sd">       Random Forests: The Jackknife and the Infinitesimal Jackknife&quot;, Journal</span>
<span class="sd">       of Machine Learning Research vol. 15, pp. 1625-1651, 2014.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">inbag</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">inbag</span> <span class="o">=</span> <span class="n">calc_inbag</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">forest</span><span class="p">)</span>

    <span class="n">pred_centered</span> <span class="o">=</span> <span class="n">_centered_prediction_forest</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
    <span class="n">n_trees</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">n_estimators</span>
    <span class="n">V_IJ</span> <span class="o">=</span> <span class="n">_core_computation</span><span class="p">(</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">inbag</span><span class="p">,</span> <span class="n">pred_centered</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">,</span> <span class="n">memory_constrained</span><span class="p">,</span> <span class="n">memory_limit</span>
    <span class="p">)</span>
    <span class="n">V_IJ_unbiased</span> <span class="o">=</span> <span class="n">_bias_correction</span><span class="p">(</span><span class="n">V_IJ</span><span class="p">,</span> <span class="n">inbag</span><span class="p">,</span> <span class="n">pred_centered</span><span class="p">,</span> <span class="n">n_trees</span><span class="p">)</span>

    <span class="c1"># Correct for cases where resampling is done without replacement:</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">inbag</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">variance_inflation</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">inbag</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">V_IJ_unbiased</span> <span class="o">*=</span> <span class="n">variance_inflation</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">calibrate</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">V_IJ_unbiased</span>

    <span class="k">if</span> <span class="n">V_IJ_unbiased</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">20</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No calibration with n_samples &lt;= 20: &quot;</span><span class="p">,</span> 
                 <span class="s2">&quot;consider using more n_estimators in your model, &quot;</span><span class="p">,</span> 
                 <span class="s2">&quot;for more accurate ci and to avoid negative values.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">V_IJ_unbiased</span>
    <span class="k">if</span> <span class="n">calibrate</span><span class="p">:</span>
        <span class="c1"># Calibration is a correction for converging quicker to the case of infinite n_estimators,</span>
        <span class="c1"># as presented in Wager (2014) http://jmlr.org/papers/v15/wager14a.html</span>
        <span class="n">calibration_ratio</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">n_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_trees</span> <span class="o">/</span> <span class="n">calibration_ratio</span><span class="p">)</span>
        <span class="n">new_forest</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">forest</span><span class="p">)</span>
        <span class="n">random_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_forest</span><span class="o">.</span><span class="n">estimators_</span><span class="p">))[:</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_sample</span><span class="p">)]</span>
        <span class="n">new_forest</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_forest</span><span class="o">.</span><span class="n">estimators_</span><span class="p">)[</span><span class="n">random_idx</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">new_forest</span><span class="p">,</span> <span class="s2">&quot;_seeds&quot;</span><span class="p">):</span>
            <span class="n">new_forest</span><span class="o">.</span><span class="n">_seeds</span> <span class="o">=</span> <span class="n">new_forest</span><span class="o">.</span><span class="n">_seeds</span><span class="p">[</span><span class="n">random_idx</span><span class="p">]</span>

        <span class="n">new_forest</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_sample</span><span class="p">)</span>

        <span class="n">results_ss</span> <span class="o">=</span> <span class="n">random_forest_error</span><span class="p">(</span>
            <span class="n">new_forest</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">X_test</span><span class="p">,</span>
            <span class="n">calibrate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">memory_constrained</span><span class="o">=</span><span class="n">memory_constrained</span><span class="p">,</span>
            <span class="n">memory_limit</span><span class="o">=</span><span class="n">memory_limit</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Use this second set of variance estimates</span>
        <span class="c1"># to estimate scale of Monte Carlo noise</span>
        <span class="n">sigma2_ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">results_ss</span> <span class="o">-</span> <span class="n">V_IJ_unbiased</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">n_sample</span> <span class="o">/</span> <span class="n">n_trees</span>
        <span class="n">sigma2</span> <span class="o">=</span> <span class="p">(</span><span class="n">delta</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delta</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delta</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma2_ss</span>

        <span class="c1"># Use Monte Carlo noise scale estimate for empirical Bayes calibration</span>
        <span class="n">V_IJ_calibrated</span> <span class="o">=</span> <span class="n">calibrateEB</span><span class="p">(</span><span class="n">V_IJ_unbiased</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">V_IJ_calibrated</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016--, Kivan Polimis, Ariel Rokem, Bryna Hazelton, The University of Washington.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>